import streamlit as st
import tensorflow as tf
from tensorflow import keras
from keras import backend as K
import numpy as np
import cv2
import mediapipe as mp
from mediapipe.tasks import python as mp_tasks
from mediapipe.tasks.python import vision as mp_vision
import joblib
import gdown
from typing import List, Tuple
import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
import os
import tempfile
import seaborn as sns
from scipy.stats import pearsonr
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="AI å§¿å‹¢è©•ä¼°ç³»çµ±",
    page_icon="ğŸƒâ€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®šç¾©è‡ªè¨‚çš„ RMSE æå¤±å‡½æ•¸
def rmse(y_true, y_pred):
    return K.sqrt(K.mean(K.square(y_pred - y_true)))

# âš ï¸ å®šç¾©æª”æ¡ˆè·¯å¾‘å’Œ Google Drive ID
MODEL_PATH = "CNN_squat_best.keras"
SCALER_PATH = "scaler_CNN_squat_best.pkl"
POSE_MODEL_PATH = "pose_landmark_heavy.tflite"

# âš ï¸ å·²ä½¿ç”¨æ‚¨æä¾›çš„æª”æ¡ˆ ID
MODEL_FILE_ID = "1rfKtqXaC9ZXhk52_qdaIVVQq_0EFa573"
SCALER_FILE_ID = "15OJwaejPv7D8HIudP7koxfEfNPdGMsyB"
POSE_FILE_ID = "1-yGZVfF8nQsRETziIFgS-jFKpHC-1xLo"

@st.cache_resource
def download_file_from_google_drive(file_id, output_path):
    """å¾ Google Drive ä¸‹è¼‰æª”æ¡ˆï¼Œå¦‚æœæª”æ¡ˆä¸å­˜åœ¨å‰‡ä¸‹è¼‰"""
    if not os.path.exists(output_path):
        st.info(f"æ­£åœ¨å¾ Google Drive ä¸‹è¼‰ {output_path}...")
        try:
            gdown.download(f'https://drive.google.com/uc?id={file_id}', output_path, quiet=False)
            st.success(f"âœ… {output_path} ä¸‹è¼‰å®Œæˆï¼")
        except Exception as e:
            st.error(f"âŒ æª”æ¡ˆä¸‹è¼‰å¤±æ•—: {str(e)}")
            st.stop()
    return output_path

class PoseEvaluator:
    def __init__(self, model_path: str, scaler_path: str):
        # ä½¿ç”¨ custom_objects åƒæ•¸è¼‰å…¥æ¨¡å‹
        self.model = keras.models.load_model(model_path, custom_objects={'rmse': rmse})
        self.scaler = joblib.load(scaler_path)

        # è¨­å®š mediapipe ä½¿ç”¨ CPU
        base_options = mp_tasks.BaseOptions(
            model_asset_path=POSE_MODEL_PATH,
            delegate=mp_tasks.BaseOptions.Delegate.CPU
        )
        options = mp_vision.PoseLandmarkerOptions(
            base_options=base_options,
            min_pose_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            min_pose_presence_confidence=0.5
        )
        self.pose_landmarker = mp_vision.PoseLandmarker.create_from_options(options)

    def process_frame(self, frame: np.ndarray) -> List[float]:
        """è™•ç†å–®å€‹å½±æ ¼ä¸¦æå–é—œéµé»ï¼ˆä½¿ç”¨ç›¸å°åº§æ¨™ï¼‰"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image = mp_tasks.core.Image.create_from_numpy_array(rgb_frame)
        detection_result = self.pose_landmarker.detect(mp_image)
        if detection_result.pose_landmarks:
            landmarks = detection_result.pose_landmarks[0]
            landmarks_np = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in landmarks])
            left_hip = landmarks_np[23, :3]
            right_hip = landmarks_np[24, :3]
            hip_center = (left_hip + right_hip) / 2
            left_shoulder = landmarks_np[11, :3]
            right_shoulder = landmarks_np[12, :3]
            shoulder_center = (left_shoulder + right_shoulder) / 2
            scale = np.linalg.norm(shoulder_center - hip_center)
            if scale == 0:
                scale = 1
            normalized_landmarks = (landmarks_np[:, :3] - hip_center) / scale
            normalized_landmarks = np.hstack((normalized_landmarks, landmarks_np[:, 3:4]))
            return normalized_landmarks.flatten().tolist()
        return None

    def analyze_predictions(self, predictions: np.ndarray) -> dict:
        """åˆ†æé æ¸¬çµæœä¸¦è¿”å›è©³ç´°çµ±è¨ˆè³‡è¨Š"""
        predictions = predictions.flatten()
        return {
            'min': np.min(predictions),
            'max': np.max(predictions),
            'mean': np.mean(predictions),
            'median': np.median(predictions),
            'std': np.std(predictions),
            '25th_percentile': np.percentile(predictions, 25),
            '75th_percentile': np.percentile(predictions, 75)
        }

    def evaluate_video(self, video_path: str, progress_callback=None) -> Tuple[float, dict, np.ndarray]:
        """è©•ä¼°å½±ç‰‡ä¸­çš„å‹•ä½œä¸¦è¿”å›è©³ç´°åˆ†æ"""
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        keypoints_list = []
        frame_count = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame_count += 1
            if progress_callback:
                progress_callback(frame_count / total_frames)
            keypoints = self.process_frame(frame)
            if keypoints:
                keypoints_list.append(keypoints)
        cap.release()
        if len(keypoints_list) == 0:
            return None, None, None
        keypoints_array = np.array(keypoints_list)
        keypoints_array = self.scaler.transform(keypoints_array)
        keypoints_array = keypoints_array.reshape(-1, 33, 4)
        predictions = self.model.predict(keypoints_array, batch_size=32, verbose=0)
        stats = self.analyze_predictions(predictions)
        stats.update({
            'total_frames': total_frames,
            'effective_frames': len(keypoints_list),
            'fps': fps,
            'duration': total_frames/fps,
            'detection_rate': (len(keypoints_list)/total_frames)*100
        })
        return stats['mean'], stats, predictions

def create_interactive_plots(predictions):
    predictions_flat = predictions.flatten()
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('é æ¸¬å€¼éš¨æ™‚é–“è®ŠåŒ–', 'é æ¸¬å€¼åˆ†å¸ƒ'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}]]
    )
    fig.add_trace(go.Scatter(y=predictions_flat, mode='lines', name='é æ¸¬å€¼', line=dict(color='blue')), row=1, col=1)
    fig.add_hline(y=np.mean(predictions_flat), line_dash="dash", line_color="red", annotation_text="å¹³å‡å€¼", row=1, col=1)
    fig.add_trace(go.Histogram(x=predictions_flat, name='åˆ†å¸ƒ', nbinsx=30, opacity=0.7), row=1, col=2)
    fig.update_layout(height=400, showlegend=True, title_text="å§¿å‹¢è©•ä¼°åˆ†æçµæœ")
    return fig

def main():
    st.title("ğŸƒâ€â™‚ï¸ AI å§¿å‹¢è©•ä¼°ç³»çµ±")
    st.markdown("---")
    
    # âš ï¸ åœ¨é€™è£¡å‘¼å«ä¸‹è¼‰å‡½æ•¸ï¼Œç¢ºä¿æª”æ¡ˆå­˜åœ¨
    model_path_local = download_file_from_google_drive(MODEL_FILE_ID, MODEL_PATH)
    scaler_path_local = download_file_from_google_drive(SCALER_FILE_ID, SCALER_PATH)
    pose_model_path_local = download_file_from_google_drive(POSE_FILE_ID, POSE_MODEL_PATH)
    
    # å´é‚Šæ¬„ - è¨­å®šåƒæ•¸
    st.sidebar.header("âš™ï¸ ç³»çµ±è¨­å®š")
    model_path = st.sidebar.text_input("æ¨¡å‹æª”æ¡ˆè·¯å¾‘", value=model_path_local, help="è¨“ç·´å¥½çš„ Keras æ¨¡å‹æª”æ¡ˆ")
    scaler_path = st.sidebar.text_input("æ¨™æº–åŒ–å™¨æª”æ¡ˆè·¯å¾‘", value=scaler_path_local, help="ç”¨æ–¼è³‡æ–™æ¨™æº–åŒ–çš„ scaler æª”æ¡ˆ")
    
    files_exist = all([os.path.exists(model_path), os.path.exists(scaler_path), os.path.exists(pose_model_path_local)])
    
    if not files_exist:
        st.error("âŒ è«‹ç¢ºèªæ¨¡å‹æª”æ¡ˆå’Œæ¨™æº–åŒ–å™¨æª”æ¡ˆå·²å­˜åœ¨")
        st.stop()
    
    try:
        with st.spinner("æ­£åœ¨è¼‰å…¥æ¨¡å‹..."):
            evaluator = PoseEvaluator(model_path, scaler_path)
        st.sidebar.success("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        st.sidebar.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
        st.stop()
    
    col1, col2 = st.columns([2, 1])
    with col1:
        st.header("ğŸ“¹ å½±ç‰‡ä¸Šå‚³èˆ‡åˆ†æ")
        uploaded_file = st.file_uploader(
            "é¸æ“‡è¦åˆ†æçš„å½±ç‰‡æª”æ¡ˆ",
            type=['mp4', 'avi', 'mov', 'mkv'],
            help="æ”¯æ´æ ¼å¼ï¼šMP4, AVI, MOV, MKV"
        )
        if uploaded_file is not None:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                tmp_file.write(uploaded_file.read())
                temp_video_path = tmp_file.name
            st.success(f"âœ… å½±ç‰‡å·²ä¸Šå‚³: {uploaded_file.name}")
            cap = cv2.VideoCapture(temp_video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()
            st.info(f"ğŸ“Š å½±ç‰‡è³‡è¨Š: {duration:.2f}ç§’ | {total_frames}å¹€ | {fps:.1f} FPS | {width}x{height}")
            if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                def update_progress(progress):
                    progress_bar.progress(progress)
                    status_text.text(f"åˆ†æé€²åº¦: {progress*100:.1f}%")
                try:
                    avg_score, detailed_stats, predictions = evaluator.evaluate_video(
                        temp_video_path,
                        progress_callback=update_progress
                    )
                    if avg_score is not None:
                        status_text.text("âœ… åˆ†æå®Œæˆï¼")
                        st.session_state['analysis_results'] = {
                            'avg_score': avg_score,
                            'detailed_stats': detailed_stats,
                            'predictions': predictions,
                            'video_name': uploaded_file.name
                        }
                    else:
                        st.error("âŒ æœªæª¢æ¸¬åˆ°æœ‰æ•ˆçš„å§¿å‹¢æ•¸æ“šï¼Œè«‹æª¢æŸ¥å½±ç‰‡å“è³ª")
                except Exception as e:
                    st.error(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                finally:
                    if os.path.exists(temp_video_path):
                        os.unlink(temp_video_path)
    with col2:
        st.header("ğŸ“ˆ å³æ™‚çµ±è¨ˆ")
        if 'analysis_results' in st.session_state:
            results = st.session_state['analysis_results']
            stats = results['detailed_stats']
            st.metric(label="å¹³å‡å§¿å‹¢åˆ†æ•¸", value=f"{results['avg_score']:.2f}", delta=f"Â±{stats['std']:.2f}")
            col2_1, col2_2 = st.columns(2)
            with col2_1:
                st.metric("æœ€é«˜åˆ†", f"{stats['max']:.2f}")
                st.metric("æª¢æ¸¬ç‡", f"{stats['detection_rate']:.1f}%")
            with col2_2:
                st.metric("æœ€ä½åˆ†", f"{stats['min']:.2f}")
                st.metric("å½±ç‰‡é•·åº¦", f"{stats['duration']:.1f}ç§’")
    if 'analysis_results' in st.session_state:
        st.markdown("---")
        st.header("ğŸ“Š è©³ç´°åˆ†æçµæœ")
        results = st.session_state['analysis_results']
        predictions = results['predictions']
        fig = create_interactive_plots(predictions)
        st.plotly_chart(fig, use_container_width=True)
        st.subheader("ğŸ“‹ çµ±è¨ˆæ‘˜è¦")
        stats_df = pd.DataFrame([
            ['å½±ç‰‡åç¨±', results['video_name']], ['å¹³å‡åˆ†æ•¸', f"{results['avg_score']:.2f}"],
            ['æ¨™æº–å·®', f"{results['detailed_stats']['std']:.2f}"], ['æœ€å°å€¼', f"{results['detailed_stats']['min']:.2f}"],
            ['æœ€å¤§å€¼', f"{results['detailed_stats']['max']:.2f}"], ['ä¸­ä½æ•¸', f"{results['detailed_stats']['median']:.2f}"],
            ['25th ç™¾åˆ†ä½', f"{results['detailed_stats']['25th_percentile']:.2f}"],
            ['75th ç™¾åˆ†ä½', f"{results['detailed_stats']['75th_percentile']:.2f}"],
            ['ç¸½å¹€æ•¸', f"{results['detailed_stats']['total_frames']}"],
            ['æœ‰æ•ˆå¹€æ•¸', f"{results['detailed_stats']['effective_frames']}"],
            ['æª¢æ¸¬ç‡', f"{results['detailed_stats']['detection_rate']:.1f}%"],
            ['å½±ç‰‡é•·åº¦', f"{results['detailed_stats']['duration']:.2f} ç§’"]
        ], columns=['é …ç›®', 'æ•¸å€¼'])
        st.dataframe(stats_df, use_container_width=True)
            
if __name__ == "__main__":
    main()