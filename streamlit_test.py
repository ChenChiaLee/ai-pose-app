import streamlit as st
import tensorflow as tf
from tensorflow import keras
import numpy as np
import cv2
import mediapipe as mp
import joblib
from typing import List, Tuple
import matplotlib.pyplot as plt
from datetime import datetime
import pandas as pd
import os
import tempfile
import seaborn as sns
from scipy.stats import pearsonr
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="AI å§¿å‹¢è©•ä¼°ç³»çµ±",
    page_icon="ğŸƒâ€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

class PoseEvaluator:
    def __init__(self, model_path: str, scaler_path: str, ground_truth_path: str = None):
        self.model = keras.models.load_model(model_path)
        self.scaler = joblib.load(scaler_path)
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            model_complexity=2
        )
        
        # è¼‰å…¥çœŸå¯¦æ¨™ç±¤è³‡æ–™
        self.ground_truth_df = None
        if ground_truth_path and os.path.exists(ground_truth_path):
            self.ground_truth_df = pd.read_csv(ground_truth_path)

    def process_frame(self, frame: np.ndarray) -> List[float]:
        """è™•ç†å–®å€‹å½±æ ¼ä¸¦æå–é—œéµé»ï¼ˆä½¿ç”¨ç›¸å°åº§æ¨™ï¼‰"""
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(rgb_frame)
        
        if results.pose_landmarks:
            landmarks = np.array([[lm.x, lm.y, lm.z, lm.visibility] for lm in results.pose_landmarks.landmark])
            
            # ç²å–å·¦é«– (23) å’Œå³é«– (24) çš„åº§æ¨™
            left_hip = landmarks[23, :3]
            right_hip = landmarks[24, :3]
            hip_center = (left_hip + right_hip) / 2
            
            # ç²å–å·¦è‚© (11) å’Œå³è‚© (12) çš„åº§æ¨™
            left_shoulder = landmarks[11, :3]
            right_shoulder = landmarks[12, :3]
            shoulder_center = (left_shoulder + right_shoulder) / 2
            
            # è¨ˆç®—æ¨™æº–åŒ–å°ºåº¦
            scale = np.linalg.norm(shoulder_center - hip_center)
            if scale == 0:
                scale = 1
            
            # å°‡æ‰€æœ‰é—œéµé»è½‰æ›ç‚ºç›¸å°æ–¼é«–é—œç¯€ä¸­å¿ƒçš„åº§æ¨™ï¼Œä¸¦é€²è¡Œå°ºåº¦æ¨™æº–åŒ–
            normalized_landmarks = (landmarks[:, :3] - hip_center) / scale
            normalized_landmarks = np.hstack((normalized_landmarks, landmarks[:, 3:4]))
            
            return normalized_landmarks.flatten().tolist()
        return None

    def analyze_predictions(self, predictions: np.ndarray) -> dict:
        """åˆ†æé æ¸¬çµæœä¸¦è¿”å›è©³ç´°çµ±è¨ˆè³‡è¨Š"""
        predictions = predictions.flatten()
        
        return {
            'min': np.min(predictions),
            'max': np.max(predictions),
            'mean': np.mean(predictions),
            'median': np.median(predictions),
            'std': np.std(predictions),
            '25th_percentile': np.percentile(predictions, 25),
            '75th_percentile': np.percentile(predictions, 75)
        }

    def get_ground_truth(self, video_filename: str) -> float:
        """æ ¹æ“šå½±ç‰‡åç¨±å¾è³‡æ–™é›†ä¸­ç²å–çœŸå¯¦æ¨™ç±¤å€¼"""
        if self.ground_truth_df is None:
            return None
            
        video_id = os.path.splitext(video_filename)[0]
        
        if 'video_id' in self.ground_truth_df.columns:
            matching_row = self.ground_truth_df[self.ground_truth_df['video_id'] == video_id]
            if not matching_row.empty:
                label_col = 'total_score'
                if label_col in self.ground_truth_df.columns:
                    return matching_row[label_col].values[0]
                else:
                    numeric_cols = matching_row.select_dtypes(include=np.number).columns
                    if len(numeric_cols) > 0:
                        return matching_row[numeric_cols[0]].values[0]
        return None

    def get_frame_ground_truths(self, video_id: str) -> List[float]:
        """ç²å–ç‰¹å®šå½±ç‰‡ä¸­æ¯ä¸€å¹€çš„çœŸå¯¦æ¨™ç±¤åˆ†æ•¸"""
        if self.ground_truth_df is None:
            return []
    
        if {'video_id', 'frame', 'knee_score'}.issubset(self.ground_truth_df.columns):
            df = self.ground_truth_df
            frame_scores = df[df['video_id'] == video_id].sort_values(by='frame')['knee_score'].tolist()
            return frame_scores
        return []

    def evaluate_video(self, video_path: str, progress_callback=None) -> Tuple[float, dict, np.ndarray]:
        """è©•ä¼°å½±ç‰‡ä¸­çš„å‹•ä½œä¸¦è¿”å›è©³ç´°åˆ†æ"""
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        keypoints_list = []
        frame_count = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
                
            frame_count += 1
            if progress_callback:
                progress_callback(frame_count / total_frames)
            
            keypoints = self.process_frame(frame)
            if keypoints:
                keypoints_list.append(keypoints)
        
        cap.release()
        
        if len(keypoints_list) == 0:
            return None, None, None
            
        # æ•¸æ“šé è™•ç†
        keypoints_array = np.array(keypoints_list)
        keypoints_array = self.scaler.transform(keypoints_array)
        keypoints_array = keypoints_array.reshape(-1, 33, 4)
        
        # é€²è¡Œé æ¸¬
        predictions = self.model.predict(keypoints_array, batch_size=32, verbose=0)
        stats = self.analyze_predictions(predictions)
        
        # æ·»åŠ é¡å¤–çµ±è¨ˆè³‡è¨Š
        stats.update({
            'total_frames': total_frames,
            'effective_frames': len(keypoints_list),
            'fps': fps,
            'duration': total_frames/fps,
            'detection_rate': (len(keypoints_list)/total_frames)*100
        })
        
        return stats['mean'], stats, predictions

def create_interactive_plots(predictions, ground_truth=None, frame_truths=None):
    """å‰µå»ºäº’å‹•å¼åœ–è¡¨"""
    predictions_flat = predictions.flatten()
    
    # å‰µå»ºå­åœ–
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('é æ¸¬å€¼éš¨æ™‚é–“è®ŠåŒ–', 'é æ¸¬å€¼åˆ†å¸ƒ', 'çµ±è¨ˆæ‘˜è¦'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"type": "table"}, {"secondary_y": False}]]
    )
    
    # 1. é æ¸¬å€¼éš¨æ™‚é–“è®ŠåŒ–
    fig.add_trace(
        go.Scatter(y=predictions_flat, mode='lines', name='é æ¸¬å€¼', line=dict(color='blue')),
        row=1, col=1
    )
    fig.add_hline(y=np.mean(predictions_flat), line_dash="dash", line_color="red", 
                  annotation_text="å¹³å‡å€¼", row=1, col=1)
    
    if ground_truth is not None:
        fig.add_hline(y=ground_truth, line_dash="solid", line_color="green", 
                      annotation_text="çœŸå¯¦å€¼", row=1, col=1)
    
    # 2. é æ¸¬å€¼åˆ†å¸ƒç›´æ–¹åœ–
    fig.add_trace(
        go.Histogram(x=predictions_flat, name='åˆ†å¸ƒ', nbinsx=30, opacity=0.7),
        row=1, col=2
    )
    
    # 3. çµ±è¨ˆæ‘˜è¦è¡¨æ ¼
    stats_data = [
        ['å¹³å‡å€¼', f'{np.mean(predictions_flat):.2f}'],
        ['ä¸­ä½æ•¸', f'{np.median(predictions_flat):.2f}'],
        ['æ¨™æº–å·®', f'{np.std(predictions_flat):.2f}'],
        ['æœ€å°å€¼', f'{np.min(predictions_flat):.2f}'],
        ['æœ€å¤§å€¼', f'{np.max(predictions_flat):.2f}']
    ]
    
    if ground_truth is not None:
        stats_data.append(['çœŸå¯¦å€¼', f'{ground_truth:.2f}'])
        stats_data.append(['èª¤å·®', f'{abs(np.mean(predictions_flat) - ground_truth):.2f}'])
    
    fig.add_trace(
        go.Table(
            header=dict(values=['çµ±è¨ˆé …ç›®', 'æ•¸å€¼']),
            cells=dict(values=[[row[0] for row in stats_data], 
                              [row[1] for row in stats_data]])
        ),
        row=2, col=1
    )
    '''
    # 4. å¦‚æœæœ‰é€å¹€çœŸå¯¦å€¼ï¼Œé¡¯ç¤ºæ¯”è¼ƒ
    if frame_truths and len(frame_truths) == len(predictions_flat):
        fig.add_trace(
            go.Scatter(y=predictions_flat, mode='lines', name='é æ¸¬å€¼', line=dict(color='blue')),
            row=2, col=2
        )
        fig.add_trace(
            go.Scatter(y=frame_truths, mode='lines', name='çœŸå¯¦å€¼', line=dict(color='red', dash='dash')),
            row=2, col=2
        )
        
        # è¨ˆç®—ç›¸é—œä¿‚æ•¸
        corr, _ = pearsonr(predictions_flat, frame_truths)
        fig.add_annotation(
            text=f"ç›¸é—œä¿‚æ•¸: {corr:.3f}",
            xref="x4", yref="y4",
            x=len(predictions_flat)*0.7, y=max(max(predictions_flat), max(frame_truths))*0.9,
            showarrow=False,
            bgcolor="white",
            bordercolor="black"
        )
    '''
    fig.update_layout(height=800, showlegend=True, title_text="å§¿å‹¢è©•ä¼°åˆ†æçµæœ")
    return fig

def main():
    st.title("ğŸƒâ€â™‚ï¸ AI å§¿å‹¢è©•ä¼°ç³»çµ±")
    st.markdown("---")
    
    # å´é‚Šæ¬„ - è¨­å®šåƒæ•¸
    st.sidebar.header("âš™ï¸ ç³»çµ±è¨­å®š")
    
    # æ¨¡å‹æª”æ¡ˆè·¯å¾‘è¨­å®š
    model_path = st.sidebar.text_input(
        "æ¨¡å‹æª”æ¡ˆè·¯å¾‘", 
        value="Alexnet_squat0603.keras",
        help="è«‹è¼¸å…¥è¨“ç·´å¥½çš„ Keras æ¨¡å‹æª”æ¡ˆè·¯å¾‘"
        )

    scaler_path = st.sidebar.text_input(
        "æ¨™æº–åŒ–å™¨æª”æ¡ˆè·¯å¾‘", 
        value="scaler_Alexnet_squat0603.pkl",
        help="è«‹è¼¸å…¥ç”¨æ–¼è³‡æ–™æ¨™æº–åŒ–çš„ scaler æª”æ¡ˆè·¯å¾‘"
        )
    '''
    ground_truth_path = st.sidebar.text_input(
        "çœŸå¯¦æ¨™ç±¤æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰", 
        value="squat_400(0603).csv",
        help="å¦‚æœæœ‰çœŸå¯¦æ¨™ç±¤è³‡æ–™ï¼Œè«‹è¼¸å…¥ CSV æª”æ¡ˆè·¯å¾‘"
        )
    '''
    
    # æ–°å¢ä»¥ä¸‹é€™è¡Œï¼Œç”¨ä¾†é¡¯ç¤ºStreamlit Cloudä¸Šçš„æª”æ¡ˆåˆ—è¡¨
    st.sidebar.text(f"ç•¶å‰ç›®éŒ„ä¸­çš„æª”æ¡ˆ:\n{os.listdir('.')}")
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    files_exist = all([
        os.path.exists(model_path) if model_path else False,
        os.path.exists(scaler_path) if scaler_path else False
    ])
    
    if not files_exist:
        st.error("âŒ è«‹ç¢ºèªæ¨¡å‹æª”æ¡ˆå’Œæ¨™æº–åŒ–å™¨æª”æ¡ˆè·¯å¾‘æ­£ç¢º")
        st.stop()
    
    # åˆå§‹åŒ–è©•ä¼°å™¨
    try:
        with st.spinner("æ­£åœ¨è¼‰å…¥æ¨¡å‹..."):
            evaluator = PoseEvaluator(model_path, scaler_path)
        st.sidebar.success("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        st.sidebar.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
        st.stop()
    
    # ä¸»è¦å…§å®¹å€åŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“¹ å½±ç‰‡ä¸Šå‚³èˆ‡åˆ†æ")
        
        # å½±ç‰‡ä¸Šå‚³
        uploaded_file = st.file_uploader(
            "é¸æ“‡è¦åˆ†æçš„å½±ç‰‡æª”æ¡ˆ",
            type=['mp4', 'avi', 'mov', 'mkv'],
            help="æ”¯æ´æ ¼å¼ï¼šMP4, AVI, MOV, MKV"
        )
        
        if uploaded_file is not None:
            # å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆåˆ°è‡¨æ™‚ä½ç½®
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                tmp_file.write(uploaded_file.read())
                temp_video_path = tmp_file.name
            
            st.success(f"âœ… å½±ç‰‡å·²ä¸Šå‚³: {uploaded_file.name}")
            
            # é¡¯ç¤ºå½±ç‰‡è³‡è¨Š
            cap = cv2.VideoCapture(temp_video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()
            
            st.info(f"ğŸ“Š å½±ç‰‡è³‡è¨Š: {duration:.2f}ç§’ | {total_frames}å¹€ | {fps:.1f} FPS | {width}x{height}")
            
            # åˆ†ææŒ‰éˆ•
            if st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_progress(progress):
                    progress_bar.progress(progress)
                    status_text.text(f"åˆ†æé€²åº¦: {progress*100:.1f}%")
                
                try:
                    # åŸ·è¡Œåˆ†æ
                    avg_score, detailed_stats, predictions = evaluator.evaluate_video(
                        temp_video_path, 
                        progress_callback=update_progress
                    )
                    
                    if avg_score is not None:
                        status_text.text("âœ… åˆ†æå®Œæˆï¼")
                        
                        # å„²å­˜çµæœåˆ° session state
                        st.session_state['analysis_results'] = {
                            'avg_score': avg_score,
                            'detailed_stats': detailed_stats,
                            'predictions': predictions,
                            'video_name': uploaded_file.name
                        }
                        
                        # ç²å–çœŸå¯¦æ¨™ç±¤ï¼ˆå¦‚æœæœ‰ï¼‰
                        ground_truth = evaluator.get_ground_truth(uploaded_file.name)
                        video_id = os.path.splitext(uploaded_file.name)[0]
                        frame_truths = evaluator.get_frame_ground_truths(video_id)
                        
                        st.session_state['ground_truth'] = ground_truth
                        st.session_state['frame_truths'] = frame_truths
                        
                    else:
                        st.error("âŒ æœªæª¢æ¸¬åˆ°æœ‰æ•ˆçš„å§¿å‹¢æ•¸æ“šï¼Œè«‹æª¢æŸ¥å½±ç‰‡å“è³ª")
                        
                except Exception as e:
                    st.error(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                
                finally:
                    # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                    if os.path.exists(temp_video_path):
                        os.unlink(temp_video_path)
    
    with col2:
        st.header("ğŸ“ˆ å³æ™‚çµ±è¨ˆ")
        
        if 'analysis_results' in st.session_state:
            results = st.session_state['analysis_results']
            stats = results['detailed_stats']
            
            # é¡¯ç¤ºä¸»è¦åˆ†æ•¸
            st.metric(
                label="å¹³å‡å§¿å‹¢åˆ†æ•¸",
                value=f"{results['avg_score']:.2f}",
                delta=f"Â±{stats['std']:.2f}"
            )
            
            # é¡¯ç¤ºå…¶ä»–çµ±è¨ˆè³‡è¨Š
            col2_1, col2_2 = st.columns(2)
            with col2_1:
                st.metric("æœ€é«˜åˆ†", f"{stats['max']:.2f}")
                st.metric("æª¢æ¸¬ç‡", f"{stats['detection_rate']:.1f}%")
            with col2_2:
                st.metric("æœ€ä½åˆ†", f"{stats['min']:.2f}")
                st.metric("å½±ç‰‡é•·åº¦", f"{stats['duration']:.1f}ç§’")
            
            # çœŸå¯¦å€¼æ¯”è¼ƒï¼ˆå¦‚æœæœ‰ï¼‰
            if 'ground_truth' in st.session_state and st.session_state['ground_truth'] is not None:
                ground_truth = st.session_state['ground_truth']
                error = abs(results['avg_score'] - ground_truth)
                relative_error = (error / ground_truth) * 100
                
                st.markdown("### ğŸ¯ æº–ç¢ºåº¦åˆ†æ")
                st.metric("çœŸå¯¦åˆ†æ•¸", f"{ground_truth:.2f}")
                st.metric("çµ•å°èª¤å·®", f"{error:.2f}")
                st.metric("ç›¸å°èª¤å·®", f"{relative_error:.1f}%")
    
    # çµæœè¦–è¦ºåŒ–å€åŸŸ
    if 'analysis_results' in st.session_state:
        st.markdown("---")
        st.header("ğŸ“Š è©³ç´°åˆ†æçµæœ")
        
        results = st.session_state['analysis_results']
        predictions = results['predictions']
        ground_truth = st.session_state.get('ground_truth')
        frame_truths = st.session_state.get('frame_truths')
        
        # å‰µå»ºäº’å‹•å¼åœ–è¡¨
        fig = create_interactive_plots(predictions, ground_truth, frame_truths)
        st.plotly_chart(fig, use_container_width=True)
        
        # è©³ç´°çµ±è¨ˆè¡¨æ ¼
        st.subheader("ğŸ“‹ çµ±è¨ˆæ‘˜è¦")
        stats_df = pd.DataFrame([
            ['å½±ç‰‡åç¨±', results['video_name']],
            ['å¹³å‡åˆ†æ•¸', f"{results['avg_score']:.2f}"],
            ['æ¨™æº–å·®', f"{results['detailed_stats']['std']:.2f}"],
            ['æœ€å°å€¼', f"{results['detailed_stats']['min']:.2f}"],
            ['æœ€å¤§å€¼', f"{results['detailed_stats']['max']:.2f}"],
            ['ä¸­ä½æ•¸', f"{results['detailed_stats']['median']:.2f}"],
            ['25th ç™¾åˆ†ä½', f"{results['detailed_stats']['25th_percentile']:.2f}"],
            ['75th ç™¾åˆ†ä½', f"{results['detailed_stats']['75th_percentile']:.2f}"],
            ['ç¸½å¹€æ•¸', f"{results['detailed_stats']['total_frames']}"],
            ['æœ‰æ•ˆå¹€æ•¸', f"{results['detailed_stats']['effective_frames']}"],
            ['æª¢æ¸¬ç‡', f"{results['detailed_stats']['detection_rate']:.1f}%"],
            ['å½±ç‰‡é•·åº¦', f"{results['detailed_stats']['duration']:.2f} ç§’"]
        ], columns=['é …ç›®', 'æ•¸å€¼'])
        
        st.dataframe(stats_df, use_container_width=True)
'''       
        # ä¸‹è¼‰çµæœ
        if st.button("ğŸ“¥ ä¸‹è¼‰åˆ†æçµæœ"):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # æº–å‚™ä¸‹è¼‰æ•¸æ“š
            download_data = {
                'video_name': results['video_name'],
                'analysis_time': timestamp,
                'average_score': results['avg_score'],
                'detailed_stats': results['detailed_stats'],
                'frame_predictions': predictions.flatten().tolist()
            }
            
            if ground_truth is not None:
                download_data['ground_truth'] = ground_truth
                download_data['absolute_error'] = abs(results['avg_score'] - ground_truth)
            
            # è½‰æ›ç‚º JSON å­—ç¬¦ä¸²
            import json
            json_str = json.dumps(download_data, indent=2, ensure_ascii=False)
            
            st.download_button(
                label="ä¸‹è¼‰ JSON æ ¼å¼çµæœ",
                data=json_str,
                file_name=f"pose_analysis_{timestamp}.json",
                mime="application/json"
            )
'''
if __name__ == "__main__":
    main()